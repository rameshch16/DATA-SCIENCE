{"cells":[{"metadata":{"_uuid":"3fbf4765e0efd9f31ace2169836faefa0086c06f"},"cell_type":"markdown","source":"# Amazon fine food review - sentimental analysis using KNN"},{"metadata":{"_uuid":"7d95f10102e62638302920b088c7a6e50b6b4ef3"},"cell_type":"markdown","source":"This dataset consists of reviews of fine foods from amazon. The data span a period of more than 10 years, including all ~500,000 reviews up to October 2012. Reviews include product and user information, ratings, and a plain text review. It also includes reviews from all other Amazon categories. "},{"metadata":{"_uuid":"35c6b5545af23c6157eb5b12a32573122753f222"},"cell_type":"markdown","source":"# Overview"},{"metadata":{"_uuid":"29a9b8996005f7671ba92082084dc2abbb80ad4d"},"cell_type":"markdown","source":"This Dataset contains 10 features/independent variables/predictors etc. We will look at the reviews of each and every customers and will analyze them using k-nearest neighbors algorithm for now and in next part we will apply algorithms like naive bayes, logistic regression, svm, decision tree etc.\n\n\n<br>**Id** Row Id </br>\n<br>**ProductId** Unique identifier for the product </br>\n<br>**UserId** Unqiue identifier for the user</br>\n<br>**ProfileName** Profile name of the user</br>\n<br>**HelpfulnessNumerator** Number of users who found the review helpful</br>\n<br>**HelpfulnessDenominator** Number of users who indicated whether they found the review helpful</br>\n<br>**Score** Rating between 1 and 5</br>\n<br>**Time** Timestamp for the review</br>\n<br>**Summary** Brief summary of the review</br>\n<br>**Text** Text of the review</br>"},{"metadata":{"_uuid":"22d6d5ed06ef52279a3756c213fec9c271f06e06"},"cell_type":"markdown","source":"<br> **Objective** </br>\n\nWe should never forget our obective,  If foget, we may not reach to destination. So, here our objective is to predict whether a review is **-ve(Rating 1 or 2) or +ve(Rating 4 or 5 )**. let's get started..."},{"metadata":{"_uuid":"27ca1d4f5236e6624baea16ce2e15f3e8714d5e2"},"cell_type":"markdown","source":"# Table of Content"},{"metadata":{"_uuid":"502def2c04256ddf766441dfe958e82e40c0f7aa"},"cell_type":"markdown","source":"1.  Loading dataset\n2.  Data Preprocessing()\n3. Cross-Validation to find optimal K value\n4. Apply KNN\n    * KNN Model on Bow(bag of words)\n    * KNN Model on TFIDF(2-gram) \n    * KNN Model on average Word2Vec\n    * KNN Model on TFIDF Word2Vec\n5. Score Prediction\n6. Confusion Matrix "},{"metadata":{"_uuid":"5bf0c040b273b05a69eac414dbd749981f4f4911"},"cell_type":"markdown","source":"\n"},{"metadata":{"trusted":true,"_uuid":"aa9f60301fdb3ae48c5c5389194fc8110262a074","collapsed":true},"cell_type":"code","source":"# imported necessary libraries\nimport numpy as np\nimport pandas as pd\nimport sqlite3\nimport matplotlib.pyplot as plt\n#from sklearn.cross_validation import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n#from sklearn.model_selection import cross_val_score\nfrom sklearn.cross_validation import cross_val_score\nfrom collections import Counter\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import model_selection\nfrom sklearn import cross_validation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"73f9724bd7d9f9bfa834ee0b2cde187e085bfa6d"},"cell_type":"code","source":"# using the SQLite Table to read data.\ncon = sqlite3.connect('../input/database.sqlite')\n#con = sqlite3.connect('database.sqlite') \n\n#filtering only positive and negative reviews i.e. \n# not taking into consideration those reviews with Score=3\nfiltered_data = pd.read_sql_query(\"\"\"SELECT * FROM Reviews WHERE Score != 3\"\"\", con) \n\n# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.\ndef partition(x):\n    if x < 3:\n        return 'negative'\n    return 'positive'\n\n#changing reviews with score less than 3 to be positive and vice-versa\nactualScore = filtered_data['Score']\npositiveNegative = actualScore.map(partition) \nfiltered_data['Score'] = positiveNegative","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9841d50669ec83a127afb200c662a543cf5ad107","collapsed":true},"cell_type":"code","source":"filtered_data.shape #looking at the number of attributes and size of the data\nfiltered_data.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b82aa5dc19178eb8547625bee32b0504f58e241d"},"cell_type":"markdown","source":"# Exploratory Data Analysis\n# Data Cleaning: Deduplication\n\nIt is observed (as shown in the table below) that the reviews data had many duplicate entries. Hence it was necessary to remove duplicates in order to get unbiased results for the analysis of the data. Following is an example:\n"},{"metadata":{"trusted":true,"_uuid":"6b6c3b7215022f5c2fa9994e5a543b6318ff2501","collapsed":true},"cell_type":"code","source":"display= pd.read_sql_query(\"\"\"\nSELECT *\nFROM Reviews\nWHERE Score != 3 AND UserId=\"AR5J8UI46CURR\"\nORDER BY ProductID\n\"\"\", con)\ndisplay","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"27a3d8b23cad684267041f38700b627583bd4b6d"},"cell_type":"markdown","source":"As can be seen above the same user has multiple reviews of the with the same values for HelpfulnessNumerator, HelpfulnessDenominator, Score, Time, Summary and Text  and on doing analysis it was found that <br>\n<br> \nProductId=B000HDOPZG was Loacker Quadratini Vanilla Wafer Cookies, 8.82-Ounce Packages (Pack of 8)<br>\n<br> \nProductId=B000HDL1RQ was Loacker Quadratini Lemon Wafer Cookies, 8.82-Ounce Packages (Pack of 8) and so on<br>\n\nIt was inferred after analysis that reviews with same parameters other than ProductId belonged to the same product just having different flavour or quantity. Hence in order to reduce redundancy it was decided to eliminate the rows having same parameters.<br>\n\nThe method used for the same was that we first sort the data according to ProductId and then just keep the first similar product review and delelte the others. for eg. in the above just the review for ProductId=B000HDL1RQ remains. This method ensures that there is only one representative for each product and deduplication without sorting would lead to possibility of different representatives still existing for the same product."},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"e55fc8483dd5468ed012e21e38d18ddae1b34d19"},"cell_type":"code","source":"#Sorting data according to ProductId in ascending order\nsorted_data = filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"788b9dc03f947fe45b0d75ddd1c8bbc503668dc3","collapsed":true},"cell_type":"code","source":"#Deduplication of entries\nfinal = sorted_data.drop_duplicates(subset = {\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep ='first', inplace=False)\nfinal.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8b1a86d5d248115b7c805e93e004f0d447f7fbf","collapsed":true},"cell_type":"code","source":"#Checking to see how much % of data still remains\n(final['Id'].size*1.0)/(filtered_data['Id'].size*1.0)*100","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f60c10fbbba5cad0aa3b0e14685f156e0ec1db21"},"cell_type":"markdown","source":"Observation:- It was also seen that in two rows given below the value of HelpfulnessNumerator is greater than HelpfulnessDenominator which is not practically possible hence these two rows too are removed from calcualtions"},{"metadata":{"trusted":true,"_uuid":"59f67a4ae0d67dc7b850226ae27d83ed2ba99475","collapsed":true},"cell_type":"code","source":"display= pd.read_sql_query(\"\"\"\nSELECT *\nFROM Reviews\nWHERE Score != 3 AND Id=44737 OR Id=64422\nORDER BY ProductID\n\"\"\", con)\ndisplay","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3ba5f685df83a007825745d0fa1a4351ac76f2bb"},"cell_type":"code","source":"final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"543377780a9c746c04f7885fc5ae213ab1c56a16","collapsed":true},"cell_type":"code","source":"#Before starting the next phase of preprocessing lets see the number of entries left\nprint(final.shape)\n\n#How many positive and negative reviews are present in our dataset?\nfinal['Score'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"77e0cc75e654bbe54fd8d70f40603a00d2b3dbc2"},"cell_type":"markdown","source":"# Text Preprocessing: Stemming, stop-word removal and Lemmatization.\n\nNow that we have finished deduplication our data requires some preprocessing before we go on further with analysis and making the prediction model.\n\nHence in the Preprocessing phase we do the following in the order below:-\n\n1. Begin by removing the html tags\n2. Remove any punctuations or limited set of special characters like , or . or # etc.\n3. Check if the word is made up of english letters and is not alpha-numeric\n4. Check to see if the length of the word is greater than 2 (as it was researched that there is no adjective in 2-letters)\n5. Convert the word to lowercase\n6. Remove Stopwords\n7. Finally Snowball Stemming the word (it was obsereved to be better than Porter Stemming)<br>\n\nAfter which we collect the words used to describe positive and negative reviews"},{"metadata":{"trusted":true,"_uuid":"ccfe3730aac28ef721459297ef42afb005f3fcb3","collapsed":true},"cell_type":"code","source":"# find sentences containing HTML tags\nimport re\ni=0;\nfor sent in final['Text'].values:\n    if (len(re.findall('<.*?>', sent))):\n        print(i)\n        print(sent)\n        break;\n    i += 1;    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bbce465e9c3d90ab260e9037e181d7bed6a4039c","collapsed":true},"cell_type":"code","source":"import re\n# Tutorial about Python regular expressions: https://pymotw.com/2/re/\nimport string\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\nimport nltk\n\nstop = set(stopwords.words('english')) #set of stopwords\nsno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n\ndef cleanhtml(sentence): #function to clean the word of any html-tags\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, ' ', sentence)\n    return cleantext\ndef cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n    return  cleaned\nprint(stop)\nprint('************************************')\nprint(sno.stem('tasty'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"f58acbb1ecf466c97f31a6b43fdd9f60f10feb97"},"cell_type":"code","source":"#Code for implementing step-by-step the checks mentioned in the pre-processing phase\n# this code takes a while to run as it needs to run on 500k sentences.\ni=0\nstr1=' '\nfinal_string=[]\nall_positive_words=[] # store words from +ve reviews here\nall_negative_words=[] # store words from -ve reviews here.\ns=''\nfor sent in final['Text'].values:\n    filtered_sentence=[]\n    #print(sent);\n    sent=cleanhtml(sent) # remove HTMl tags\n    for w in sent.split():\n        for cleaned_words in cleanpunc(w).split():\n            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n                if(cleaned_words.lower() not in stop):\n                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n                    filtered_sentence.append(s)\n                    if (final['Score'].values)[i] == 'positive': \n                        all_positive_words.append(s) #list of all words used to describe positive reviews\n                    if(final['Score'].values)[i] == 'negative':\n                        all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n                else:\n                    continue\n            else:\n                continue \n    #print(filtered_sentence)\n    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n    #print(\"***********************************************************************\")\n    \n    final_string.append(str1)\n    i+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"679e8eaa0be36c72a6bbaab0f2d1550a81d739a4"},"cell_type":"code","source":"final['CleanedText']=final_string #adding a column of CleanedText which displays the data after pre-processing of the review ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"cd859960f504ebe1f8b194fd1d49590bf07d3524"},"cell_type":"code","source":"final.head(3) #below the processed review can be seen in the CleanedText Column \n\n\n# store final table into an SQlLite table for future.\nconn = sqlite3.connect('final.sqlite')\nc=conn.cursor()\nconn.text_factory = str\nfinal.to_sql('Reviews', conn, schema=None, if_exists='replace', index=True, index_label=None, chunksize=None, dtype=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5d84ba9d78a1a2b4aecd7ecbca42300868ef040d","collapsed":true},"cell_type":"code","source":"import sqlite3\ncon = sqlite3.connect(\"final.sqlite\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"867bd2475bf898622a9d3484e1e1815f687196d8","collapsed":true},"cell_type":"code","source":"cleaned_data = pd.read_sql_query(\"select * from Reviews\", con)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa2e32bc620c2986e632aebcc9e5f55af5b0b5aa","collapsed":true},"cell_type":"code","source":"cleaned_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8031970ed4562a4b10a5c63aca7ad6cb769c2855","collapsed":true},"cell_type":"code","source":"# To randomly sample 10k points from both class\n\ndata_pos = cleaned_data[cleaned_data[\"Score\"] == \"positive\"].sample(n = 10000)\ndata_neg = cleaned_data[cleaned_data[\"Score\"] == \"negative\"].sample(n = 10000)\nfinal_20k = pd.concat([data_pos, data_neg])\nfinal_20k.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4e862c657993323b16115aafcd7bc1599f2cd578","collapsed":true},"cell_type":"code","source":"# Sorting data based on time\nfinal_20k[\"Time\"] = pd.to_datetime(final_20k[\"Time\"], unit = \"s\")\nfinal_20k = final_20k.sort_values(by = \"Time\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df9f5a962e4821960d3cdc73b22a0dd9e07be1ca"},"cell_type":"markdown","source":"<h1>Bag of Word</h1>"},{"metadata":{"trusted":true,"_uuid":"0668eacc727b67b0868d9e4b59f3e2fef660710a","collapsed":true},"cell_type":"code","source":"# Fuction to compute k value\ndef k_classifier_brute(X_train, y_train):\n    # creating odd list of K for KNN\n    myList = list(range(0,50))\n    neighbors = list(filter(lambda x: x % 2 != 0, myList))\n\n    # empty list that will hold cv scores\n    cv_scores = []\n\n    # perform 10-fold cross validation\n    for k in neighbors:\n        knn = KNeighborsClassifier(n_neighbors=k, algorithm = \"brute\")\n        scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n        cv_scores.append(scores.mean())\n\n    # changing to misclassification error\n    MSE = [1 - x for x in cv_scores]\n\n    # determining best k\n    optimal_k = neighbors[MSE.index(min(MSE))]\n    print('\\nThe optimal number of neighbors is %d.' % optimal_k)\n\n    # plot misclassification error vs k \n    plt.plot(neighbors, MSE)\n\n    for xy in zip(neighbors, np.round(MSE,3)):\n        plt.annotate('(%s, %s)' % xy, xy=xy, textcoords='data')\n    plt.title(\"Misclassification Error vs K\")\n    plt.xlabel('Number of Neighbors K')\n    plt.ylabel('Misclassification Error')\n    plt.show()\n\n    print(\"the misclassification error for each k value is : \", np.round(MSE,3))\n    return optimal_k","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c6f5f3ac9eadb5d7b8d4cff7d4c180203875758","collapsed":true},"cell_type":"code","source":"# 40k data which will use to train model after vectorization\nX = final_20k[\"CleanedText\"]\nprint(\"shape of X:\", X.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"469fb98135c96b6f3740d43f6a1ba3a40f8a1fe8","collapsed":true},"cell_type":"code","source":"# class label\ny = final_20k[\"Score\"]\nprint(\"shape of y:\", y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce5a1c760e87ba2c6b5a1e99f9c513c162f60da6","collapsed":true},"cell_type":"code","source":"# split data into train and test where 70% data used to train model and 30% for test\n# final_4000[:int(len(final_4000) * 0.75)], final_4000[int(len(final_4000) * 0.75):]\nfrom sklearn.model_selection import train_test_split\nX_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\nprint(X_train.shape, y_train.shape, x_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b1e45b9e09b307d42699870887e44c5df8e40a65","collapsed":true},"cell_type":"code","source":"# Train Vectorizor\nfrom sklearn.feature_extraction.text import CountVectorizer \n\nbow = CountVectorizer()\nX_train = bow.fit_transform(X_train)\nX_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c23c2042533535d15ceb25355bc5083e785663e4","collapsed":true},"cell_type":"code","source":"# Test Vectorizor\nx_test = bow.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"524faf00326dc658df8191c02c6ae6b8e1bd53f3","collapsed":true},"cell_type":"code","source":"x_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"67d0b75a2907e2c8d26923b1dd758129e17009a5","collapsed":true},"cell_type":"code","source":"# To choose optimal_k using brute force algorithm\n\noptimal_k_bow = k_classifier_brute(X_train, y_train)\noptimal_k_bow","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4ab99962f684cc56b518f689e1be2dcd17d848c","collapsed":true},"cell_type":"code","source":"# instantiate learning model k = optimal_k\nknn_optimal = KNeighborsClassifier(n_neighbors=optimal_k_bow)\n\n# fitting the model\nknn_optimal.fit(X_train, y_train)\n#knn_optimal.fit(bow_data, y_train)\n\n# predict the response\npred = knn_optimal.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c58dc65d38798cb8743417c9d3c7fa8937bc8dee","collapsed":true},"cell_type":"code","source":"# Accuracy on train data\ntrain_acc_bow = knn_optimal.score(X_train, y_train)\nprint(\"Train accuracy\", train_acc_bow)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb3fed96fcab375fb39298b2ad081df0c315eb55","collapsed":true},"cell_type":"code","source":"# Error on train data\ntrain_err_bow = 1-train_acc_bow\nprint(\"Train Error %f%%\" % (train_err_bow))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"71e49e5834b4af521bc5dbfb4fd84b55909ac782","collapsed":true},"cell_type":"code","source":"# evaluate accuracy on test data\nacc_bow = accuracy_score(y_test, pred) * 100\nprint('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k_bow, acc_bow))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cc602bda3d1dedf800b41d30dada6155d0e7dac5","collapsed":true},"cell_type":"code","source":"# Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, pred)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c58a1af4d540bbe5f2596aec6787dd5f368d07c7","collapsed":true},"cell_type":"code","source":"# plot confusion matrix to describe the performance of classifier.\nimport seaborn as sns\nclass_label = [\"negative\", \"positive\"]\ndf_cm = pd.DataFrame(cm, index = class_label, columns = class_label)\nsns.heatmap(df_cm, annot = True, fmt = \"d\")\nplt.title(\"Confusiion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e9fba7d287e44b095b65cf57756b222d3e7455e0","collapsed":true},"cell_type":"code","source":"# To show main classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5eaffe3e3218a685be25789f8064494457c82fac"},"cell_type":"markdown","source":"**Terminology**<br>\n\n**true positives (TP):** We predicted +ve review, and review is also +ve.<br>\n**true negatives (TN):** We predicted -ve, and review is also -ve.<br>\n**false positives (FP):** We predicted +ve, but the review is not actually +ve.(Also known as a \"Type I error.\")<br>\n**false negatives (FN):** We predicted -ve, but the review is actually +ve.(Also known as a \"Type II error.\")<br>\n"},{"metadata":{"_uuid":"f6b03469fab2ecf49d400e8d125d545d29bff4f8"},"cell_type":"markdown","source":"**confusion matrix described**<br>\nIn above confusion matrix(used to describe performence of classifier)\n\n1. tn(true negative) = 1278, tp(true positive) = 2700, fn(false negative) = 349, fp(false positive) = 1673\n2. And as it is shows in classification report overall accuracy(i.e. how often is the classifier correct?) = (tp+tn)/total = (2700+1278)/6000 = ~66%\n3. And Overall error rate/misclassification rate or 1-accuracy(i.e. how often it is wrong?) --> (fn+fp)/total = (349+1673)/6000 = ~34%\n4. precision --> When it predicts +ve, how often is it correct? = tp/predicted +ve = 2700/4373 = ~62%\n5. True Positive rate(tpr)/recall --> When it is actually +ve, how often does it predict +ve? = tp/(real/true/actual +ve) = 2700/3049 = ~89%\n6. Specificity(True Negative Rate)--> When it's actually no, how often does it predict no? = tn/actual negative = 1278/2951 = ~43%. The best specificity is 1.0, whereas the worst is 0.0 .\n7. False Positive rate --> when it is actually -ve, how often does it predicted +ve = fp/actual-ve = 1673/2951 = ~57%\n8. F1 score/F-score/F-measure is weighted avg of precision and recall(tpr).\n9. support is number of elements in each class(+ve and -ve)."},{"metadata":{"_uuid":"16836708f90e335ae45e049ec5bdcedb6c4c7ead"},"cell_type":"markdown","source":"<br>**Observations**</br>\n1. From above figure(misclassification error vs optimal k) It is showing that classification error for each value of k, when k is increaseing the error is decreasing. For ex - if k = 1 then error = 38%, k = 2 error = 37% and so on.\n2. As I tested our model on unseen data(test data) the accuracy is 66% when k = 47. \n3. In confusion matrix, It is clear that out of 6k unseen data-points classifier predict 4373 +ve and 1627 -ve class label but in real 3049 were +ve and 2951 were -ve.\n4. In a nutshell we can say the generalization error is quite high means this model does not work well with unseen data."},{"metadata":{"_uuid":"f72b9f86f2442cebc6f0321b88faa148bed4752d"},"cell_type":"markdown","source":"<h1>Tf-Idf</h1>"},{"metadata":{"trusted":true,"_uuid":"1be7f21626fa8cf41abc3a727ef603f1eb11c494","collapsed":true},"cell_type":"code","source":"# data\nX = final_20k[\"CleanedText\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ca54b7247f407c09e612c4a30053c4fa70e546c","collapsed":true},"cell_type":"code","source":"# Target/class-label\ny = final_20k[\"Score\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"329d53e177fb7792df78d80e70a93f7f682aac53","collapsed":true},"cell_type":"code","source":"# Split data\nX_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\nprint(X_train.shape, x_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"a1679ca257b07876334bafdd4d86e41c634d31f0","collapsed":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n#tfidf = TfidfVectorizer()\n#tfidf_data = tfidf.fit_transform(final_4000[\"CleanedText\"])\n#tfidf_data\ntf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\nX_train = tf_idf_vect.fit_transform(X_train)\nX_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"10b1ebc227e311394d0485eaf1410287e06f3cd9","collapsed":true},"cell_type":"code","source":"# Convert test text data to its vectorizor\nx_test = tf_idf_vect.transform(x_test)\nx_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"6915c7aae3e2741f3810ec191f110f486d7afd8e","collapsed":true},"cell_type":"code","source":"# To choosing optimal_k\n\noptimal_k_tfidf = k_classifier_brute(X_train, y_train)\noptimal_k_tfidf","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"18ba5aae1add880480e5a01ca9df7ac6ea3620d5","collapsed":true},"cell_type":"code","source":"# instantiate learning model k = optimal_k\nknn_optimal = KNeighborsClassifier(n_neighbors=optimal_k_tfidf)\n\n# fitting the model\nknn_optimal.fit(X_train, y_train)\n#knn_optimal.fit(bow_data, y_train)\n    \n# predict the response\npred = knn_optimal.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b0438749217cd32140da0f85b087f88728eed8f2","collapsed":true},"cell_type":"code","source":"'''\nfrom sklearn.model_selection import validation_curve\ntrain_scores, test_scores = validation_curve(KneighborsClassifier(), X, y, cv = 10, scoring = \"accuracy\")\ntrain_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"576bec5e3c47009bb744ef780965feee5982c013","collapsed":true},"cell_type":"code","source":"# Accuracy on train data\ntrain_acc_tfidf = knn_optimal.score(X_train, y_train)\nprint(\"Train accuracy\", train_acc_tfidf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"8eb8160cd5e4c5600ddf4f4571a1c30ac0ed264e","collapsed":true},"cell_type":"code","source":"# Error on train data\ntrain_err_tfidf = 1-train_acc_tfidf\nprint(\"Train Error %f%%\" % (train_err_tfidf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f773ee0d3ad8c295853da1c33740dcfeae2ae1d6","collapsed":true},"cell_type":"code","source":"# evaluate accuracy\nacc_tfidf = accuracy_score(y_test, pred) * 100\nprint('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k_tfidf, acc_tfidf))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"33654f48f2ac09fb8768a78ad8592984cdaece0f","collapsed":true},"cell_type":"code","source":"#from sklearn.matrics import confusion_matrix\ncm = confusion_matrix(y_test, pred)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"dba9e71c10bde00264e9afbf9d988c8c7c911de8","collapsed":true},"cell_type":"code","source":"class_label = [\"negative\", \"positive\"]\ndf_cm = pd.DataFrame(cm, index = class_label, columns = class_label)\nsns.heatmap(df_cm, annot = True, fmt = \"d\")\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"284f7fe3bb00b1ff0367a8972541c43d1ce81698","collapsed":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0ea41dc0f5a41624e4e23b86f85874f45937c9a"},"cell_type":"markdown","source":"**Observations**\n1. look at the bow observations for clarifying doubt.\n2. In tfidf when the value of k = 49 which is quite high, accuracy is also good.\n3. In a nutshell we can say this model works well with unseen data."},{"metadata":{"_uuid":"3c5996b093f493163a8ee4a460c17ef82b405d74"},"cell_type":"markdown","source":"<h1> word2vec </h1>"},{"metadata":{"trusted":false,"_uuid":"0ae1058488d9b950a92c325cb6c26f04c5a75573","collapsed":true},"cell_type":"code","source":"# data\nX = final_20k[\"Text\"]\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"15996b77d93d62bac467f1d4c4baa27b8f14446c","collapsed":true},"cell_type":"code","source":"# Target/class-label\ny = final_20k[\"Score\"]\ny.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c0bbac3490cea3d61f8ead4aef44af08270a8236","collapsed":true},"cell_type":"code","source":"X_train, x_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size = 0.3)\nprint(X_train.shape, x_test.shape, y_train.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"db62cdaf227c7e327bbaadbf10be285886497be0","collapsed":true},"cell_type":"code","source":"import re\n\ndef cleanhtml(sentence): #function to clean the word of any html-tags\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, ' ', sentence)\n    return cleantext\ndef cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n    return  cleaned","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ce85e2a853d30edabdf1b6fc316924ca12085377","collapsed":true},"cell_type":"code","source":"# Train your own Word2Vec model using your own train text corpus\nimport gensim\nlist_of_sent=[]\n#for sent in final_40k['Text'].values:\nfor sent in X_train:\n    filtered_sentence=[]\n    sent=cleanhtml(sent)\n    for w in sent.split():\n        for cleaned_words in cleanpunc(w).split():\n            if(cleaned_words.isalpha()):    \n                filtered_sentence.append(cleaned_words.lower())\n            else:\n                continue \n    list_of_sent.append(filtered_sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3afa0fd3931d12462a36653a201320ae4ac2bb6b","collapsed":true},"cell_type":"code","source":"w2v_model=gensim.models.Word2Vec(list_of_sent,min_count=5,size=50, workers=4)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false,"_uuid":"f3bc850fbef51b2a9e2b77b3742242ab87d90b84","collapsed":true},"cell_type":"code","source":"w2v_model.wv.most_similar('like')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"aea608a337c0634c1ea99fad1b16c33929bc6de3","collapsed":true},"cell_type":"code","source":"w2v = w2v_model[w2v_model.wv.vocab]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1785ae355848fb7de85882a0d8d7910f0c21983a","collapsed":true},"cell_type":"code","source":"w2v.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"9d25b66eb6a145e1177e5ce09b4ca88f51604d1b","collapsed":true},"cell_type":"code","source":"# Train your own Word2Vec model using your own test text corpus\nimport gensim\nlist_of_sent_test = []\n#for sent in final_40k['Text'].values:\nfor sent in x_test:\n    filtered_sentence=[]\n    sent=cleanhtml(sent)\n    for w in sent.split():\n        for cleaned_words in cleanpunc(w).split():\n            if(cleaned_words.isalpha()):    \n                filtered_sentence.append(cleaned_words.lower())\n            else:\n                continue \n    list_of_sent_test.append(filtered_sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"76940c73043bd6ff0b07f4ce613e17f7773ef520","collapsed":true},"cell_type":"code","source":"w2v_model=gensim.models.Word2Vec(list_of_sent_test, min_count=5, size=50, workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"173e3265c1e9c18464fa0daa01ac9f7393794034","collapsed":true},"cell_type":"code","source":"w2v_model.wv.most_similar('like')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c39bbfbd943c2afc0b280e4710356397cdab43b7","collapsed":true},"cell_type":"code","source":"w2v = w2v_model[w2v_model.wv.vocab]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"218d92362ab3be5b59b7f31f8d334317fb58a673","collapsed":true},"cell_type":"code","source":"w2v.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e7a53c0cb3bad8a2682820a9ed12b51be85a3499"},"cell_type":"markdown","source":"<h1> Average Word2Vec </h1>"},{"metadata":{"trusted":false,"_uuid":"08f387052a0e4ddf0813012c9d7437cf08b95481","collapsed":true},"cell_type":"code","source":"# average Word2Vec\n# compute average word2vec for each review.\nsent_vectors = []; # the avg-w2v for each sentence/review is stored in this list\nfor sent in list_of_sent: # for each review/sentence\n    sent_vec = np.zeros(50) # as word vectors are of zero length\n    cnt_words =0; # num of words with a valid vector in the sentence/review\n    for word in sent: # for each word in a review/sentence\n        try:\n            vec = w2v_model.wv[word]\n            sent_vec += vec\n            cnt_words += 1\n        except:\n            pass\n    sent_vec /= cnt_words\n    sent_vectors.append(sent_vec)\nprint(len(sent_vectors))\nprint(len(sent_vectors[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"95c2de5b15585105225bdd602deb3d416c7e6f11","collapsed":true},"cell_type":"code","source":"# average Word2Vec\n# compute average word2vec for each review.\nsent_vectors_test = []; # the avg-w2v for each sentence/review is stored in this list\nfor sent in list_of_sent_test: # for each review/sentence\n    sent_vec = np.zeros(50) # as word vectors are of zero length\n    cnt_words =0; # num of words with a valid vector in the sentence/review\n    for word in sent: # for each word in a review/sentence\n        try:\n            vec = w2v_model.wv[word]\n            sent_vec += vec\n            cnt_words += 1\n        except:\n            pass\n    sent_vec /= cnt_words\n    sent_vectors_test.append(sent_vec)\nprint(len(sent_vectors_test))\nprint(len(sent_vectors_test[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"30b18bf8b2bf757bbfa264179a3acd47899bc852","collapsed":true},"cell_type":"code","source":"X_train = sent_vectors","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"386f98f626df5ed1bd94947930a144c5d7469fcd","collapsed":true},"cell_type":"code","source":"x_test = sent_vectors_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5cb7435e1535b4708b675b80a6f882d2d24ba350","collapsed":true},"cell_type":"code","source":"optimal_k_avgw2v = k_classifier_brute(X_train, y_train)\noptimal_k_avgw2v","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"02838f7241573b2b4e7563e91532ba7c6b6e1b4a","collapsed":true},"cell_type":"code","source":"# instantiate learning model k = optimal_k\nknn_optimal = KNeighborsClassifier(n_neighbors=optimal_k_avgw2v)\n\n# fitting the model\nknn_optimal.fit(X_train, y_train)\n#knn_optimal.fit(bow_data, y_train)\n    \n# predict the response\npred = knn_optimal.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3e85e1f01fa142b3c4349f2202a535b143dee437","collapsed":true},"cell_type":"code","source":"# Accuracy on train data\ntrain_acc_avgw2v = knn_optimal.score(X_train, y_train)\nprint(\"Train accuracy\", train_acc_avgw2v)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"76996173c3436cfd9d554afa97d45a43a20806fd","collapsed":true},"cell_type":"code","source":"# Error on train data\ntrain_err_avgw2v = 1-train_acc_avgw2v\nprint(\"Train Error %f%%\" % (train_err_avgw2v))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f0fd30457f705e1ba155742291e86cae22d94de5","collapsed":true},"cell_type":"code","source":"# evaluate accuracy\nacc_avg_w2v = accuracy_score(y_test, pred) * 100\nprint('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k_avgw2v, acc_avg_w2v))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"eca68ce9d3975c0ec1af0aef51064e7d34d79cfe","collapsed":true},"cell_type":"code","source":"print(\"Test Error %f%%\" %-(100-(acc_avg_w2v)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1980d2c2c3c0416af9ef7e4eb0a8db12d1808f9f","collapsed":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, pred)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"de390b5491a439d28305138a593287bde893b852","collapsed":true},"cell_type":"code","source":"class_label = [\"negative\", \"positive\"]\ndf_cm = pd.DataFrame(cm, index = class_label, columns = class_label)\nsns.heatmap(df_cm, annot = True, fmt = \"d\")\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"42dab71a2fb8b6c065869b2585b394301ab32489","collapsed":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7dcf607d7cbb98504a7005de3338d2be75cbabcc"},"cell_type":"markdown","source":"**Observations**"},{"metadata":{"_uuid":"3ba6529011a9586c3530b3e49f0004d022b3d98c"},"cell_type":"markdown","source":"<h1> Tf-Idf weighted Word2Vec </h1>"},{"metadata":{"trusted":false,"_uuid":"f3d3b5a5cf0a915a2d6265a1be62d4f4776ee1f0","collapsed":true},"cell_type":"code","source":"# TF-IDF weighted Word2Vec\ntfidf_feat = tf_idf_vect.get_feature_names() # tfidf words/col-names\n# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n\ntfidf_sent_vectors = []; # the tfidf-w2v for each sentence/review is stored in this list\nrow=0;\nfor sent in list_of_sent: # for each review/sentence\n    sent_vec = np.zeros(50) # as word vectors are of zero length\n    weight_sum =0; # num of words with a valid vector in the sentence/review\n    for word in sent: # for each word in a review/sentence\n        try:\n            vec = w2v_model.wv[word]\n            # obtain the tf_idfidf of a word in a sentence/review\n            tfidf = final_tf_idf[row, tfidf_feat.index(word)]\n            sent_vec += (vec * tf_idf)\n            weight_sum += tf_idf\n        except:\n            pass\n    sent_vec /= weight_sum\n    tfidf_sent_vectors.append(sent_vec)\n    row += 1  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"30a5f590fa08323c7d4330b9ca27ec676370ce2e","collapsed":true},"cell_type":"code","source":"len(tfidf_sent_vectors)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d5cd2b1f5d1a317b106c69ba9e49148f3894b6c1","collapsed":true},"cell_type":"code","source":"X_train = tfidf_sent_vectors","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"1eee5ebde8ba23939a6c9a0491c19fce094bd54a","collapsed":true},"cell_type":"code","source":"# TF-IDF weighted Word2Vec\ntfidf_feat = tf_idf_vect.get_feature_names() # tfidf words/col-names\n# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n\ntfidf_sent_vectors_test = []; # the tfidf-w2v for each sentence/review is stored in this list\nrow=0;\nfor sent in list_of_sent_test: # for each review/sentence\n    sent_vec = np.zeros(50) # as word vectors are of zero length\n    weight_sum =0; # num of words with a valid vector in the sentence/review\n    for word in sent: # for each word in a review/sentence\n        try:\n            vec = w2v_model.wv[word]\n            # obtain the tf_idfidf of a word in a sentence/review\n            tfidf = final_tf_idf[row, tfidf_feat.index(word)]\n            sent_vec += (vec * tf_idf)\n            weight_sum += tf_idf\n        except:\n            pass\n    sent_vec /= weight_sum\n    tfidf_sent_vectors_test.append(sent_vec)\n    row += 1  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"d56186dc25b5da6c559aa6c7ac039886a490dd98","collapsed":true},"cell_type":"code","source":"len(tfidf_sent_vectors_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b3d3c6366c269974ce94a2c90f593336a36bd019","collapsed":true},"cell_type":"code","source":"x_test = tfidf_sent_vectors_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"ebecc0b53a6c0d5d0b75c107e2e96e92af37fe48","collapsed":true},"cell_type":"code","source":"X_train = np.nan_to_num(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"dd3f0cea8129a2851a242a9e16c5d95a998a1999","collapsed":true},"cell_type":"code","source":"x_test = np.nan_to_num(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"dd02a9d00f1452c38e3d0ce6dcc0273dad764f7b","collapsed":true},"cell_type":"code","source":"#X_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"f20bd94f15d11a81057634653b050eec4a7bce07","collapsed":true},"cell_type":"code","source":"optimal_k_tfidf_w2v = k_classifier_brute(X_train, y_train)\noptimal_k_tfidf_w2v","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"dfdcaf05e51ec1e43704edad39f9700ec63c8ea0","collapsed":true},"cell_type":"code","source":"# instantiate learning model k = optimal_k\nknn_optimal = KNeighborsClassifier(n_neighbors=optimal_k_tfidf_w2v)\n\n# fitting the model\nknn_optimal.fit(X_train, y_train)\n#knn_optimal.fit(bow_data, y_train)\n    \n# predict the response\npred = knn_optimal.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"2e1969d3721ec4858000d89afdb4a03e77c26eec","collapsed":true},"cell_type":"code","source":"# Accuracy on train data\ntrain_acc_tfidf_w2v = knn_optimal.score(X_train, y_train)\nprint(\"Train accuracy\", train_acc_tfidf_w2v)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"b573ad63f3d5942a7d75e81d503456cc52733034","collapsed":true},"cell_type":"code","source":"# Error on train data\ntrain_err_tfidf_w2v = 1-train_acc_tfidf_w2v\nprint(\"Train Error %f%%\" % (train_err_tfidf_w2v))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"51d02cdda206587c680808db31699b421dbd105f","collapsed":true},"cell_type":"code","source":"# evaluate accuracy\nacc_tfidf_w2v = accuracy_score(y_test, pred) * 100\nprint('\\nThe accuracy of the knn classifier for k = %d is %f%%' % (optimal_k_tfidf_w2v, acc_tfidf_w2v))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"33cd90c573946aa5da8b94100880af154e05203a","collapsed":true},"cell_type":"code","source":"print(\"Test Error %f%%\" %-(100-(acc_tfidf_w2v)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"4452847ee33f4d037da8542db178d9afe8322d09","collapsed":true},"cell_type":"code","source":"cm = confusion_matrix(y_test, pred)\ncm","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"c1754f919bb4a9f8539f8775ca3c604036a57ab7","collapsed":true},"cell_type":"code","source":"class_label = [\"negative\", \"positive\"]\ndf_cm = pd.DataFrame(cm, index = class_label, columns = class_label)\nsns.heatmap(df_cm, annot = True, fmt = \"d\")\nplt.title(\"Confusion Matrix\")\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"5d1422eae835c952f713393c49df383679d330a1","collapsed":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, pred))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e5d47a7ba9623f794275748cdce8414677fccd1"},"cell_type":"markdown","source":"**Observations**\n1. The tfidf_w2v model is looks like dumb model because it is biased towards majority class, as the total # of actual +ve class was 3023(true positive) and classifier predicted all points as +ve class."},{"metadata":{"_uuid":"33f0661f586c66b52e556958e5e4e7919e98fc3d"},"cell_type":"markdown","source":"**Conclusions**\n1. As in \"knn with tfidf\" when k = 49 the accuracy is quite good than other models. In this model, train_error and test_error is low.\n2. As we know when a model performs good on training data but poor performence on unseen data(test data)i.e. its dependent on training data only, tends towards overfits and when a model perform poor performence on training data and good performence on test data i.e. it fails to learn relationship in training data tends towards underfit. We need to balance between both i.e. reduce training error and reduce error between training and testing error.\n3. Another concept bias vs variance is also related with underfitting and overfitting. when a model has high bias and low variance tend towards underfitting and its reverse- high variance and low bias called overfitting and we balanced using cross-validataion. As it is shown in below table where first three models have low trainig error and test error. But the accuracy it low which we can boost using some techniques.\n3. There are lot more things to write here but for now that's all. Will look more in next excercise."},{"metadata":{"trusted":false,"_uuid":"5d11e53a91f145ca44345955f9fb3d60adb7dfd5","collapsed":true},"cell_type":"code","source":"# model\nmodels = pd.DataFrame({'Model': ['KNN with Bow', \"KNN with TFIDF\", \"KNN with Avg_w2v\", \"KNN with tfidf_w2v\"], 'Hyper Parameter(K)': [optimal_k_bow, optimal_k_tfidf, optimal_k_avgw2v, optimal_k_tfidf_w2v], 'Train Error': [train_err_bow, train_err_tfidf, train_err_avgw2v, train_err_tfidf_w2v], 'Test Error': [100-acc_bow, 100-acc_tfidf, 100-acc_avg_w2v, 100-acc_tfidf_w2v], 'Accuracy': [acc_bow, acc_tfidf, acc_avg_w2v, acc_tfidf_w2v]}, columns = [\"Model\", \"Hyper Parameter(K)\", \"Train Error\", \"Test Error\", \"Accuracy\"])\nmodels.sort_values(by='Accuracy', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false,"_uuid":"3eeadcf6be35eeffb728471f3e28996edfbd69de","collapsed":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}